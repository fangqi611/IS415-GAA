{
  "hash": "d4b3a6604aa8e90be139098e0e442dfc",
  "result": {
    "markdown": "---\ntitle: \"Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan\"\ndate: \"March 3, 2024\"\ndate-modified: \"last-modified\"\nformat: \n  html:\n    fontsize: 18px\nexecute:\n  echo: true\n  eval: true\n  freeze: true\n  warning: false\n  message: false\n  fig_retine: 3\neditor: visual\n---\n\n\n# 0. Getting Started\n\nWe need to ensure that sf, sfdep, tmap, tidyverse, knitr, GWmodel, dplyr and plotly packages of R are currently installed in our R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr, GWmodel, dplyr, plotly)\n```\n:::\n\n\n# 1. Overview of Datasets\n\nLet's analyse and understand more the datasets that we will be importing.\n\n## 1.1 Dataset 1: TAIWAN_VILLAGE_2020\n\nThis dataset is from Taiwan's government page \"https://data.gov.tw/en/datasets/130549\". It is in ESRI shapefile format, a geospatial data of a village boundary of Tainan, Taiwan.\n\nThe code chunk below using \"st_read()\" of sf package imports \"TAIWAN_VILLAGE_2020\" shapefile into R. The imported shapefile will be simple features Object of sf known as tainan.\n\nNote that tainan_sf here is a sf object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_sf <- st_read(dsn = \"data/geospatial\", layer = \"TAINAN_VILLAGE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `TAINAN_VILLAGE' from data source \n  `/Users/fangqilim/fangqi611/IS415-GAA/Take-home_Ex/Take-home_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n```\n:::\n:::\n\n\nWe will learn how to bring this geospatial data \"TAIWAN_VILLAGE_2020\" and its associated attribute table \"Dengue_Daily.csv\" (mentioned below) into R environment later on.\n\n## 1.2 Dataset 2: Dengue_Daily.csv\n\nAs mentioned above, we will now import \"Dengue_Daily.csv\" into R by using read_csv() of readr package. The output is a R dataframe class. This data is an aspatial data of reported dengue cases in Taiwan since 1998 from Taiwan CDC Open Data Portal \"https://data.cdc.gov.tw/en/dataset/dengue-daily-determined-cases-1998\" and these cases are already confirmed.\n\nWe will also be renaming these 4 columns: 1. ONSET_DATE = \"發病日\", 2. CITY = \"居住縣市\", 3. LONGITUDE = \"最小統計區中心點X\", 4. LATITUDE = \"最小統計區中心點Y\"\n\nDo note that for this dengue dataframe, we are only concerned with columns 1, 3 and 4 for our study, the renamed names in English are also their definitions in English.\n\nWe will then use mutate() from dyplyr to create new columns, ONSET_YEAR, ONSET_MONTH and EPIWEEK to perform our analysis on the number of cases per week for each village during epidemiology week 31st to 50th of year 2023.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue <- read_csv(\"data/aspatial/Dengue_Daily.csv\") %>%\n  rename(ONSET_DATE = \"發病日\",\n         CITY = \"居住縣市\",\n         LONGITUDE = \"最小統計區中心點X\",\n         LATITUDE = \"最小統計區中心點Y\") %>%\n  mutate(ONSET_YEAR = year(ONSET_DATE),\n         ONSET_MONTH = month(ONSET_DATE,\n                             label = TRUE,\n                             abbr = TRUE),\n         EPIWEEK = epiweek(ONSET_DATE))\n```\n:::\n\n\n## 1.3 Filtering the Data & Performing Relational Joint\n\n### 1.3.1 Filtering the Data\n\nBefore performing a relational joint, we need to a study area layer in tainan in sf polygon features. We are going to filter it to village level and confine it to D01, D02, D04, D06, D07, D08, D32 and D39 as that is our area of study for this assignment. We will also be changing the crs to \"3824\" which is TWD97, Taiwan's CRS in order to perform an intersection later with the dengue dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_sf <- tainan_sf %>%\n  filter(TOWNID %in% c(\"D01\", \"D02\", \"D04\", \"D06\", \"D07\", \"D08\", \"D32\", \"D39\")) %>%\n  st_transform(crs = 3824)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_sf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 258 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\nFirst 10 features:\n      VILLCODE COUNTYNAME TOWNNAME VILLNAME       VILLENG COUNTYID COUNTYCODE\n1  67000350032     臺南市   安南區   青草里  Qingcao Vil.        D      67000\n2  67000270011     臺南市   仁德區   保安里   Bao'an Vil.        D      67000\n3  67000370005     臺南市   中西區   赤嵌里  Chihkan Vil.        D      67000\n4  67000330004     臺南市     南區   大成里  Dacheng Vil.        D      67000\n5  67000350028     臺南市   安南區   城北里 Chengbei Vil.        D      67000\n6  67000350030     臺南市   安南區   城南里 Chengnan Vil.        D      67000\n7  67000370009     臺南市   中西區   法華里    Fahua Vil.        D      67000\n8  67000350017     臺南市   安南區   海南里   Hainan Vil.        D      67000\n9  67000350049     臺南市   安南區   國安里   Guo'an Vil.        D      67000\n10 67000350018     臺南市   安南區   溪心里    Xixin Vil.        D      67000\n   TOWNID TOWNCODE NOTE                       geometry\n1     D06 67000350 <NA> POLYGON ((120.1176 23.08387...\n2     D32 67000270 <NA> POLYGON ((120.2304 22.93544...\n3     D08 67000370 <NA> POLYGON ((120.2012 22.99966...\n4     D02 67000330 <NA> POLYGON ((120.1985 22.98147...\n5     D06 67000350 <NA> POLYGON ((120.1292 23.06512...\n6     D06 67000350 <NA> POLYGON ((120.1246 23.06904...\n7     D08 67000370 <NA> POLYGON ((120.2094 22.98452...\n8     D06 67000350 <NA> POLYGON ((120.175 23.02218,...\n9     D06 67000350 <NA> POLYGON ((120.1866 23.02766...\n10    D06 67000350 <NA> POLYGON ((120.1834 23.06086...\n```\n:::\n:::\n\n\nAs there are \"None\" values under LONGITUDE and LATITUDE fields, we will be removing them by connverting to\"NA\" using as.numeric() function, then remove them using is.na() function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue$LONGITUDE <- as.numeric(dengue$LONGITUDE)\ndengue$LATITUDE <- as.numeric(dengue$LATITUDE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue <- dengue[!is.na(as.numeric(dengue$LONGITUDE)),]\ndengue <- dengue[!is.na(as.numeric(dengue$LATITUDE)),]\n```\n:::\n\n\nWe will also need to change dengue dataframe to Taiwan CRS which is TWD97/3824 to perform an intersection with tainan dataframe later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue <- st_as_sf(dengue, \n                   coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                   crs=3824)\n\ndengue\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 106081 features and 27 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 118.3081 ymin: 21.92574 xmax: 121.9826 ymax: 26.15617\nGeodetic CRS:  TWD97\n# A tibble: 106,081 × 28\n   ONSET_DATE 個案研判日 通報日     性別  年齡層 CITY   居住鄉鎮 居住村里\n * <date>     <chr>      <date>     <chr> <chr>  <chr>  <chr>    <chr>   \n 1 1998-01-02 None       1998-01-07 男    40-44  屏東縣 屏東市   None    \n 2 1998-01-03 None       1998-01-14 男    30-34  屏東縣 東港鎮   None    \n 3 1998-01-13 None       1998-02-18 男    55-59  宜蘭縣 宜蘭市   None    \n 4 1998-01-15 None       1998-01-23 男    35-39  高雄市 苓雅區   None    \n 5 1998-01-20 None       1998-02-04 男    55-59  宜蘭縣 五結鄉   None    \n 6 1998-01-23 None       1998-02-02 男    40-44  新北市 新店區   None    \n 7 1998-01-26 None       1998-02-19 女    65-69  台北市 北投區   None    \n 8 1998-02-11 None       1998-02-13 女    25-29  台南市 南區     None    \n 9 1998-02-16 None       1998-02-24 男    20-24  高雄市 楠梓區   None    \n10 1998-02-17 None       1998-02-23 女    30-34  高雄市 鳳山區   None    \n# ℹ 106,071 more rows\n# ℹ 20 more variables: 最小統計區 <chr>, 一級統計區 <chr>, 二級統計區 <chr>,\n#   感染縣市 <chr>, 感染鄉鎮 <chr>, 感染村里 <chr>, 是否境外移入 <chr>,\n#   感染國家 <chr>, 確定病例數 <dbl>, 居住村里代碼 <chr>, 感染村里代碼 <chr>,\n#   血清型 <chr>, 內政部居住縣市代碼 <chr>, 內政部居住鄉鎮代碼 <chr>,\n#   內政部感染縣市代碼 <chr>, 內政部感染鄉鎮代碼 <chr>, ONSET_YEAR <dbl>,\n#   ONSET_MONTH <ord>, EPIWEEK <dbl>, geometry <POINT [°]>\n```\n:::\n:::\n\n\nRemember, we need to confine the dengue dataframe to epidemiology week 31-50, 2023 as that is our area of study, explaining the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue <- dengue %>%\n  filter(EPIWEEK >= 31 & EPIWEEK <= 50,\n         CITY == \"台南市\",\n         ONSET_YEAR == \"2023\")\n```\n:::\n\n\nNow, after cleaning our dataset to the area we are interested, we can intersect them. We are going to save it using readr() package so save processing time. We group the dataframe by VILLCODE and EPIWEEK, dengue_vil_epi, which gives us the number of cases per week for each village during epidemiology week 31st to 50th of year 2023.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil <- st_intersection(dengue, tainan_sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(dengue_vil, \"data/rds/dengue_vil.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil <- read_rds(\"data/rds/dengue_vil.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil <- dengue_vil %>%\n  mutate(case = 1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil_epi <- dengue_vil %>%\n  group_by(VILLCODE, EPIWEEK) %>%\n  summarise(count = sum(case)) %>%\n  complete(EPIWEEK = 31:50, fill = list(count = 0)) %>%\n  st_drop_geometry()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(dengue_vil_epi, \"data/rds/dengue_vil_epi.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil_epi <- read_rds(\"data/rds/dengue_vil_epi.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(dengue_vil_epi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n:::\n\n\n### 1.3.2 Performing Relational Joint\n\nWe will now then be performing a relational joint to update Tainan's dataframe with the time frame we want with the attribute fields of the dengue dataframe using \"dengue_vil_epi\". This is performed using the left_join() function.\n\nDo note that as the left hand side data, tainan_sf, in left_join() function is a sf layer so the return output 'tainan' is also a sf object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan <- left_join(tainan_sf, dengue_vil_epi)\n\ntainan\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 258 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\nFirst 10 features:\n      VILLCODE COUNTYNAME TOWNNAME VILLNAME       VILLENG COUNTYID COUNTYCODE\n1  67000350032     臺南市   安南區   青草里  Qingcao Vil.        D      67000\n2  67000270011     臺南市   仁德區   保安里   Bao'an Vil.        D      67000\n3  67000370005     臺南市   中西區   赤嵌里  Chihkan Vil.        D      67000\n4  67000330004     臺南市     南區   大成里  Dacheng Vil.        D      67000\n5  67000350028     臺南市   安南區   城北里 Chengbei Vil.        D      67000\n6  67000350030     臺南市   安南區   城南里 Chengnan Vil.        D      67000\n7  67000370009     臺南市   中西區   法華里    Fahua Vil.        D      67000\n8  67000350017     臺南市   安南區   海南里   Hainan Vil.        D      67000\n9  67000350049     臺南市   安南區   國安里   Guo'an Vil.        D      67000\n10 67000350018     臺南市   安南區   溪心里    Xixin Vil.        D      67000\n   TOWNID TOWNCODE NOTE EPIWEEK count                       geometry\n1     D06 67000350 <NA>      NA    NA POLYGON ((120.1176 23.08387...\n2     D32 67000270 <NA>      NA    NA POLYGON ((120.2304 22.93544...\n3     D08 67000370 <NA>      NA    NA POLYGON ((120.2012 22.99966...\n4     D02 67000330 <NA>      NA    NA POLYGON ((120.1985 22.98147...\n5     D06 67000350 <NA>      NA    NA POLYGON ((120.1292 23.06512...\n6     D06 67000350 <NA>      NA    NA POLYGON ((120.1246 23.06904...\n7     D08 67000370 <NA>      NA    NA POLYGON ((120.2094 22.98452...\n8     D06 67000350 <NA>      NA    NA POLYGON ((120.175 23.02218,...\n9     D06 67000350 <NA>      NA    NA POLYGON ((120.1866 23.02766...\n10    D06 67000350 <NA>      NA    NA POLYGON ((120.1834 23.06086...\n```\n:::\n:::\n\n\n## 1.4 Describing Tainan's Dengue Cases\n\nWe are going to describe Tainan's dengue cases so by plotting a choropleth map to see it visually using the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(tainan) +\ntm_fill(col = \"VILLCODE\", \n             shape = 21,\n             style = \"quantile\", \n             palette = \"Blues\",\n             title = \"Dengue Cases\",\n             data = tainan) +\n  tm_layout(main.title = \"Dengue Cases in Tainan\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nFrom here, we can make a case that as we go up North and slightly South of Tainan, we can find more dengue cases there.\n\n# 2. Peforming Global Spatial Autocorrelation Analysis using sfdep Methods\n\n## 2.1 Deriving contiguity weights: Queen’s method\n\nWe are going to derive the contiguity weights by using spdep and tidyverse functions to define the relationships between the geographical units in our study area.\n\nQueen method is used to derive the contiguity weight as shown in the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- tainan %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 258 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\nFirst 10 features:\n                                             nb\n1                                   6, 118, 160\n2                       126, 128, 138, 168, 222\n3          68, 69, 172, 181, 184, 185, 188, 200\n4                    94, 97, 100, 104, 182, 207\n5                              12, 13, 249, 255\n6                 1, 12, 13, 118, 160, 165, 249\n7                               54, 98, 99, 201\n8  9, 73, 75, 115, 125, 144, 156, 157, 166, 186\n9                         8, 110, 115, 125, 166\n10                  11, 159, 161, 166, 236, 258\n                                                                            wt\n1                                              0.3333333, 0.3333333, 0.3333333\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                       0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n4             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n5                                                       0.25, 0.25, 0.25, 0.25\n6  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n7                                                       0.25, 0.25, 0.25, 0.25\n8                             0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n9                                                      0.2, 0.2, 0.2, 0.2, 0.2\n10            0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n      VILLCODE COUNTYNAME TOWNNAME VILLNAME       VILLENG COUNTYID COUNTYCODE\n1  67000350032     臺南市   安南區   青草里  Qingcao Vil.        D      67000\n2  67000270011     臺南市   仁德區   保安里   Bao'an Vil.        D      67000\n3  67000370005     臺南市   中西區   赤嵌里  Chihkan Vil.        D      67000\n4  67000330004     臺南市     南區   大成里  Dacheng Vil.        D      67000\n5  67000350028     臺南市   安南區   城北里 Chengbei Vil.        D      67000\n6  67000350030     臺南市   安南區   城南里 Chengnan Vil.        D      67000\n7  67000370009     臺南市   中西區   法華里    Fahua Vil.        D      67000\n8  67000350017     臺南市   安南區   海南里   Hainan Vil.        D      67000\n9  67000350049     臺南市   安南區   國安里   Guo'an Vil.        D      67000\n10 67000350018     臺南市   安南區   溪心里    Xixin Vil.        D      67000\n   TOWNID TOWNCODE NOTE EPIWEEK count                       geometry\n1     D06 67000350 <NA>      NA    NA POLYGON ((120.1176 23.08387...\n2     D32 67000270 <NA>      NA    NA POLYGON ((120.2304 22.93544...\n3     D08 67000370 <NA>      NA    NA POLYGON ((120.2012 22.99966...\n4     D02 67000330 <NA>      NA    NA POLYGON ((120.1985 22.98147...\n5     D06 67000350 <NA>      NA    NA POLYGON ((120.1292 23.06512...\n6     D06 67000350 <NA>      NA    NA POLYGON ((120.1246 23.06904...\n7     D08 67000370 <NA>      NA    NA POLYGON ((120.2094 22.98452...\n8     D06 67000350 <NA>      NA    NA POLYGON ((120.175 23.02218,...\n9     D06 67000350 <NA>      NA    NA POLYGON ((120.1866 23.02766...\n10    D06 67000350 <NA>      NA    NA POLYGON ((120.1834 23.06086...\n```\n:::\n:::\n\n\n## 2.2 Computing Global Moran’ I\n\nMoran's I is a statistic used to measure spatial autocorrelation, which is the degree to which nearby observations in a geographic space are similar to each other. Over here, we are measuring the overall spatial pattern of a variable, geometry, in our study area.\n\nGlobal Moran I test gives us the test statistic, we want to find out the moran test statistic and p-value so we can decide if this observation we have is statistically significant or not. However, we do not do this, we do Global Moran' I permutation test as shown in the code chunk below instead:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\nwm_q$VILLCODE <- as.numeric(wm_q$VILLCODE)\n\nglobal_moran_perm(wm_q$VILLCODE,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.83543, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n:::\n:::\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05.Hence, we have enough statistical evidence to reject the null hypothesis and **accept H1 that the outbreak is indeed spatial and spatio-temporal dependentas the spatial distribution are autocorrelated.**\n\n# 3. Peforming Local Spatial Autocorrelation Analysis using sfdep Methods\n\n## 3.1 Computing local Moran’s I\n\nComputing Local Moran’s I of dengue cases at village level using local_moran() of sfdep package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    VILLCODE, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\n-   ii: local moran statistic\n\n-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means\n\n-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\n\n-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for \\[0, 1\\] p-values using alternative= -p_folded_sim: the simulation folded \\[0, 0.5\\] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\n\n-   p_folded_sim: the simulation folded \\[0, 0.5\\] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\n\n-   skewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\n\n-   kurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\n## 3.2 Visualising local Moran’s I\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Tainan's Dengue Cases\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n## 3.3 Visualising p-value of local Moran’s I\n\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## 3.4 Visuaising local Moran’s I and p-value\n\nFor effective comparison, let us plot both maps next to each other as shown in the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n## 3.5 Visualising LISA map\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters of dengue cases in Tainan.\n\nAdditionally, by performing this in-depth analysis we gather more insight about the dengue problem in Tainan, the more serious and highly clustered dengue cases coloured in red are to the West of Tainan and slightly central. On the other hand, the less serious cases coloured in green are towards the East and South of Tainan.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa  %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n# 4. Hot Spot and Cold Spot Area Analysis (HCSA)\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n## 4.1 Computing local Gi\\* statistics\n\nWe need toderive a spatial weight matrix before we can compute local Gi\\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- tainan %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed.\n\nBefore computing HCSA, we need to convert VILLCODE to numeric in order to compute it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw$VILLCODE <- as.numeric(wm_idw$VILLCODE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    VILLCODE, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 258 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\n# A tibble: 258 × 23\n   gi_star    e_gi   var_gi p_value   p_sim p_folded_sim skewness kurtosis nb   \n     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>        <dbl>    <dbl>    <dbl> <nb> \n 1    1.60 0.00388 3.53e-19   1.39  1.64e-1         0.1      0.05 -0.640   <int>\n 2   -6.34 0.00388 2.97e-19  -5.39  7.18e-8         0.02     0.01 -0.219   <int>\n 3    2.99 0.00388 1.72e-19   2.55  1.08e-2         0.02     0.01 -0.0536  <int>\n 4    1.17 0.00388 1.79e-19   1.38  1.68e-1         0.2      0.1  -0.00550 <int>\n 5    1.79 0.00388 2.39e-19   2.07  3.81e-2         0.02     0.01 -0.572   <int>\n 6    2.28 0.00388 1.90e-19   2.22  2.61e-2         0.04     0.02 -0.261   <int>\n 7    1.22 0.00388 2.51e-19   0.599 5.49e-1         0.62     0.31 -0.402   <int>\n 8    2.95 0.00388 1.95e-19   2.51  1.22e-2         0.02     0.01 -0.164   <int>\n 9    1.97 0.00388 2.52e-19   2.00  4.55e-2         0.06     0.03 -0.123   <int>\n10    2.13 0.00388 2.54e-19   1.86  6.35e-2         0.04     0.02 -0.179   <int>\n# ℹ 248 more rows\n# ℹ 14 more variables: wts <list>, VILLCODE <dbl>, COUNTYNAME <chr>,\n#   TOWNNAME <chr>, VILLNAME <chr>, VILLENG <chr>, COUNTYID <chr>,\n#   COUNTYCODE <chr>, TOWNID <chr>, TOWNCODE <chr>, NOTE <chr>, EPIWEEK <dbl>,\n#   count <dbl>, geometry <POLYGON [°]>\n```\n:::\n:::\n\n\n## 4.2 Visualising Gi\\*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n## 4.3 Visualising p-value of HCSA\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n## 4.4 Visuaising local HCSA\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Tainan's Dengue Situation\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n## 4.5 Visualising hot spot and cold spot areas\n\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nThe figure above reveals that there is only one hotspot area located at the South-East of Tainan and one coldspot area slightly left of the central of Tainan. The hotspot area does coincide with our results of local Moran I method in 3.2 earlier.\n\n# 5. Emerging Hot Spot Analysis: sfdep methods\n\nThis analysis consists of 4 main steps:\n\nStep 1: Building a space-time cube, Step 2: Calculating Getis-Ord local Gi\\* statistic for each bin by using an FDR correction, Step 3: Evaluating these hot and cold spot trends by using Mann-Kendall trend test, Step 4: Categorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n## 5.1 Step 1: Creating a Time Series Cube\n\nIn the code chunk below, spacetime() of sfdep is used to create an spatio-temporal cube. We are performing step 1 of building a space-time cube.\n\nHowever, before beginning our analysis, we need to remove VILLCODE = 67000350035 because it is not aligned n x n rows with dengue_vil_epi to create a spacetime cube.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_sf <- tainan_sf %>%\n  filter(VILLCODE!= 67000350035)\n```\n:::\n\n\nWe also need to convert dengue_vil_epi into a tibble dataframe in order to create a spacetime cube.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_vil_epi <- as_tibble(dengue_vil_epi)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_st <- spacetime(dengue_vil_epi, tainan_sf,\n                      .loc_col = \"VILLCODE\",\n                      .time_col = \"EPIWEEK\")\n```\n:::\n\n\nNext, is_spacetime_cube() of sfdep package will be used to varify if our dengue_st is indeed an space-time cube object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_spacetime_cube(dengue_st)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\n## 5.2 Step 2: Computing Gi\\*\n\n### 5.2.1 Deriving the spatial weights\n\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndengue_nb <- dengue_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n```\n:::\n\n\n-   activate() of dplyr package is used to activate the geometry context\n-   mutate() of dplyr package is used to create two new columns nb and wt. Then we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n    -   The row order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\nNote that this dataset now has neighbors and weights for each time-slice.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(dengue_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 6\n  VILLCODE    EPIWEEK count                  geometry nb        wt       \n  <chr>         <dbl> <dbl>            <GEOMETRY [°]> <list>    <list>   \n1 67000350032      31     0               POINT EMPTY <int [4]> <dbl [4]>\n2 67000270011      31     1 POINT (120.2413 22.92115) <int [6]> <dbl [6]>\n3 67000370005      31     0  GEOMETRYCOLLECTION EMPTY <int [9]> <dbl [9]>\n4 67000330004      31     0  GEOMETRYCOLLECTION EMPTY <int [7]> <dbl [7]>\n5 67000350028      31     0               POINT EMPTY <int [5]> <dbl [5]>\n6 67000350030      31     0  GEOMETRYCOLLECTION EMPTY <int [7]> <dbl [7]>\n```\n:::\n:::\n\n\n### 5.2.2 Computing Gi\\*\n\nWe can use the new columns above to manually calculate the local Gi\\* for each location. We can do this by grouping by EPIWEEK and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\nIn spatial statistics, ∗Gi∗ (pronounced \"Gi star\") is a statistic used in hotspot analysis to identify spatial clusters of high or low values in a dataset.\n\nThe local Gi\\* statistic measures the degree of spatial clustering of the \"count\" variable (presumably the count of dengue cases) within a neighborhood defined by the spatial weight matrix (nb) and distance weights (wt).\n\nFor each observation within each EPIWEEK group, we identify statistically significant spatial clusters of dengue cases based on their counts and spatial relationships.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngi_stars <- dengue_nb %>% \n  group_by(EPIWEEK) %>% \n  mutate(gi_star = local_gstar_perm(\n    count, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n```\n:::\n\n\n## 5.3 Step 3: Mann-Kendall Test\n\nNow we can then evaluate each location for a trend using the Mann-Kendall test.\n\nWe are isolating and selecting data related to a specific village (over here I chose 67000320032) and still retaining information about the EPIWEEK and the corresponding local Gi\\* statistic.\n\nWe get output cpg, which is a tibble containing the results of the hotspot analysis of VILLCODE 67000320032.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbg <- gi_stars %>% \n  ungroup() %>% \n  filter(VILLCODE == \"67000320032\") |> \n  select(VILLCODE, EPIWEEK, gi_star)\n```\n:::\n\n\nNext, we plot the result of cbg by using ggplot2 functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = cbg, \n       aes(x = EPIWEEK, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\nWe can also create an interactive plot by using ggplotly() of plotly package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(data = cbg, \n       aes(x = EPIWEEK, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-6b018192971507e37906\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-6b018192971507e37906\">{\"x\":{\"data\":[{\"x\":[31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[3.2486091314466341,5.9656692631219981,4.5865094531379267,2.8834201935384893,3.6807876756759161,1.6944786970656833,2.5364226200190552,2.0025621899236947,0.40781908146582557,1.1075506265748905,1.9381612373112214,1.1663489416745667,0.50578574213429273,0.52520690260094194,0.82692236539296138,-0.78980136983160731,-0.57263611504756573,1.0874097475551556,1.373682864794584,-1.115723488491551],\"text\":[\"EPIWEEK: 31<br />gi_star:  3.2486091\",\"EPIWEEK: 32<br />gi_star:  5.9656693\",\"EPIWEEK: 33<br />gi_star:  4.5865095\",\"EPIWEEK: 34<br />gi_star:  2.8834202\",\"EPIWEEK: 35<br />gi_star:  3.6807877\",\"EPIWEEK: 36<br />gi_star:  1.6944787\",\"EPIWEEK: 37<br />gi_star:  2.5364226\",\"EPIWEEK: 38<br />gi_star:  2.0025622\",\"EPIWEEK: 39<br />gi_star:  0.4078191\",\"EPIWEEK: 40<br />gi_star:  1.1075506\",\"EPIWEEK: 41<br />gi_star:  1.9381612\",\"EPIWEEK: 42<br />gi_star:  1.1663489\",\"EPIWEEK: 43<br />gi_star:  0.5057857\",\"EPIWEEK: 44<br />gi_star:  0.5252069\",\"EPIWEEK: 45<br />gi_star:  0.8269224\",\"EPIWEEK: 46<br />gi_star: -0.7898014\",\"EPIWEEK: 47<br />gi_star: -0.5726361\",\"EPIWEEK: 48<br />gi_star:  1.0874097\",\"EPIWEEK: 49<br />gi_star:  1.3736829\",\"EPIWEEK: 50<br />gi_star: -1.1157235\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":26.228310502283108,\"r\":7.3059360730593621,\"b\":40.182648401826498,\"l\":31.415525114155255},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[30.050000000000001,50.950000000000003],\"tickmode\":\"array\",\"ticktext\":[\"35\",\"40\",\"45\",\"50\"],\"tickvals\":[35,40,45,50],\"categoryorder\":\"array\",\"categoryarray\":[\"35\",\"40\",\"45\",\"50\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(179,179,179,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.33208800332088001,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(222,222,222,1)\",\"gridwidth\":0.33208800332088001,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"EPIWEEK\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-1.4697931260722286,6.3197389007026752],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"2\",\"4\",\"6\"],\"tickvals\":[0,1.9999999999999998,4,6],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"2\",\"4\",\"6\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(179,179,179,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.33208800332088001,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(222,222,222,1)\",\"gridwidth\":0.33208800332088001,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"gi_star\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(179,179,179,1)\",\"width\":0.66417600664176002,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.8897637795275593,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"d02e439ff79d\":{\"x\":{},\"y\":{},\"type\":\"scatter\"}},\"cur_data\":\"d02e439ff79d\",\"visdat\":{\"d02e439ff79d\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nMann-Kendall trend test for the gi_star values in the cbg dataframe and spreads the results into separate columns for further analysis or visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 5\n     tau        sl     S     D  varS\n   <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 -0.642 0.0000865  -122  190.   950\n```\n:::\n:::\n\n\nIn the above result, sl (significance level) is the p-value. Since p-value is smaller than 0.05, this result tells us that there is a slight upward but insignificant trend.\n\nWe can replicate this for each location by using group_by() of dplyr package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa <- gi_stars %>%\n  group_by(EPIWEEK) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n```\n:::\n\n\n### 5.3.1 Arrange to show significant emerging hot/cold spots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)\n```\n:::\n\n\n## 5.4 Step 4: Performing Emerging Hotspot Analysis\n\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. dengue_st), and the quoted name of the variable of interest (i.e. count) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa <- emerging_hotspot_analysis(\n  x = dengue_st, \n  .var = \"count\", \n  k = 1, \n  nsim = 99\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(ehsa, \"data/rds/ehsa.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa <- read_rds(\"data/rds/ehsa.rds\")\n```\n:::\n\n\n### 5.4.1 Visualising the distribution of EHSA classes\n\nIn the code chunk below, ggplot2 functions ised used to reveal the distribution of EHSA classes as a bar chart.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\nFigure above shows that sporadic cold spots and sporadic hotspot class has the high numbers of tainan.\n\n## 5.5 Visualising EHSA\n\nIn this section, we will learn how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both tainan and ehsa together by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_sf$VILLCODE <- as.numeric(tainan_sf$VILLCODE)\nehsa$location <- as.numeric(ehsa$location)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntainan_ehsa <- tainan_sf %>%\n  left_join(ehsa,\n            by = join_by(VILLCODE == location))\n```\n:::\n\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nehsa_sig <- tainan_ehsa %>%\n  filter(p_value < 0.2)\ntmap_mode(\"plot\")\ntm_shape(tainan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-html/unnamed-chunk-54-1.png){width=672}\n:::\n:::\n\n\n# 6. Describing the Spatial Patterns Revealed\n\nWe calculated Gi\\* statistic which includes the focal (or self, or ith) observation in the neighborhood. With the calculations of the local Gi\\* for each unit of time for every geography, we can evaluate how the hotspots change over time. We incorporate time-series analysis through the use of the Mann-Kendall (MK) Trend test. This is reflected in Section 5.3 which depicts the dengue cases changing overtime in EPIWEEK as a time series form, giving us a monotonic downward trend. EHSA combines the both of these, Gi\\* statistic and MK test to evaluate if there are trends in hot or cold spots over time. EHSA utilizes a spacetime cube, for each time-slice (i.e. the complete set of geometries for a given time) the local Gi\\* is calculated\n\nThe p-values in \"tainan_ehsa\" (which is our derived output from the explanation above) categorizes each study area location into the classification of consecutive coldspot, consecutive hotspot, new coldspot, new hotspot, no pattern detected, oscilating coldspot, oscilating hotspot, sporadic coldspot and sporadic hotspot.\n\nDo note that while the different p-values categorizes them differently, but the fact that they are all smaller than 0.05 means that it suggests that there is a statistically significant clustering of events in both space and time of dengue cases in tainan.\n\nNow, getting into an in-depth analysis of the distribution of the ehsa classes (Section 5.4.1), we focus on \"Oscillating Hot Spot\" and \"Oscillating Cold Spot\" as they are the most apparent, though let's be clear of what they mean first:\n\n1.  Oscillating Cold Spot: A statistically significant cold spot for the final time-step interval that has a history of also being a statistically significant hot spot during a prior time step. Less than ninety percent of the time-step intervals have been statistically significant cold spots.\n\n2.  Oscillating Hot Spot: A statistically significant hot spot for the final time-step interval that has a history of also being a statistically significant cold spot during a prior time step. Less than ninety percent of the time-step intervals have been statistically significant hot spots.\n\nNow, after understanding what do these regions mean, we can make for the opinion and realise that the coldspots in the past are becoming hotspots (orange) and the hotspots in the past are now coldspots (green). In other words, dengue is spreading to other regions while the highly infected areas in the past are calming down now. Do note that there are overall more green areas than orange areas which means that the dengue disease is slightly decreasing but there is still a lot overall in Tainan since it is one of the hotspots.\n\nFurthermore, the fact that Tainan is facing a surge in dengue cases is not surprising, if we refer to Wei-June Chen (2018) “Dengue outbreaks and the geographic distribution of dengue vectors in Taiwan: A 20-year epidemiological analysis”, Biomedical Journal, Volume 41, Issue 5, pp. 283-289. He discussed the skewed prevalence of dengue cases in Taiwan, while the North region is relatively stable, the South region of Taiwan is heavily affected and Tainan is one of them.\n\nInterestingly, the sporadic coldspots (in pink) which means these areas has continuously faced low dengue cases overtime. According to Chen's findings, dengue cases breed at tropical climate. We can make for the opinion that maybe because most of these areas are towards the border of Tainan and facing the sea, it is less humid and not a very desirable environment for the mosquitos to breed.\n\nAdditionally, performing EHSA has provided us insight about the change of the dengue cases overtime into this situation. By comparing to Section 4.5 where we visualise local HCSA, we plotted the graph where p_sim < 0.05. Using p_sim means that we are only assessing the significance of observed spatial patterns or clusters by comparing them to what would be expected under a null hypothesis of spatial randomness. A low p_sim suggests spatial clustering or deviation from randomness.\n\nHowever, this mathematical analysis does not describe the situation and change happening in Tainan, and the scope of study using p_sim is very narrow and does not give us a lot of analysis or insight (after explaining what using p_sim means). While EHSA is able to do this by showing that dengue is spreading to other areas where more dengue cases are forming up North of Tainan.\n\nIn conclusion, if we need an overview of the dengue situation, the graph in Section 4.5 is good to get a general idea but the EHSA graph in Section 5.5 is better. It can describe and depict even a broader and more in-depth situation of the change about the dengue situation in Tainan overtime from 31st to 50th week of 2023 in each village.\n",
    "supporting": [
      "Take-home_Ex02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"../../site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"../../site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"../../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}